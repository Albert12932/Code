{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c93cd453",
   "metadata": {},
   "source": [
    "Реализуем градиентный спуск для задачи поиска оптимальных коэффициентов в MSE регрессии!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13c2a960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dd9b3c",
   "metadata": {},
   "source": [
    "Имеем 1000 объектов и 10 признаков у каждого (+таргет)!\n",
    "\n",
    "Обучим модель линейной регрессии:\n",
    "\n",
    "$$\n",
    "a(x) = \\beta_1 d_{1} + \\beta_2 d_{2} + \\beta_3 d_{3} + \\beta_4 d_{4} + \\beta_5 d_{5} + \\beta_6 d_{6} + \\beta_7 d_{7} + \\beta_8 d_{8} + \\beta_9 d_{9} + \\beta_{10} d_{10} + \\beta_0\n",
    "$$\n",
    "\n",
    "Которая минимизирует MSE:\n",
    "\n",
    "$$\n",
    "Q(a(X), Y) = \\sum_i^{1000} (a(x_i) - y_i)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c39c543",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('gradient_descent.csv')\n",
    "\n",
    "X = data.drop('target', axis=1)\n",
    "Y = pd.DataFrame({'target':data['target']})\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, Y)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa474d6",
   "metadata": {},
   "source": [
    "Обучим коэффициенты линейной регрессии с помощью библиотеки <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\"> **sklearn** </a>\n",
    "\n",
    "Отдельно выведем оценку свободного коэффициента  ($\\beta_0$ при $d_0 = 1$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84c0de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "149617d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.147094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      target\n",
       "0  30.147094"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05011218",
   "metadata": {},
   "source": [
    "Теперь вам необходимо реализовать класс для оптимизации коэффициентов линейной регрессии МНК.\n",
    "Подразумевается, что на вход алгоритм будет принимать следующие параметры:\n",
    "\n",
    "- 2 pandas датафрейма **samples** и **targets**, содержащих матрицу объектов и ветор ответов соответственно\n",
    "- значение **learning rate**, который корректирует длину вектора-градиента (чтобы он не взорвался)\n",
    "- значение **threshold**'а для критерия останова (когда мы считаем, что мы сошлись к оптимуму)\n",
    "- параметр **copy**, который позволяет либо делать изменения in-place в датафрейме, подающимся в класс, если изменения матрицы объектов в принципе при обучении имеются. Или же копировать объект при инициализации класса и возвращать новый объект, если требуется.\n",
    "\n",
    "Он будет состоять из следующих важных компонент-методов:\n",
    "\n",
    "- **add_constant_feature**: добавляет колонку с названием *constant* из единичек к переданному датафрейму **samples**. Это позволяет оценить свободный коэффициент $\\beta_0$.\n",
    "\n",
    "- **calculate_mse_loss**: вычисляет при текущих весах **self.beta** значение среднеквадратической ошибки.\n",
    "\n",
    "- **calculate_gradient**: вычисляет при текущих весах вектор-градиент по функционалу.\n",
    "\n",
    "- **iteration**: производит итерацию градиентного спуска, то есть обновляет веса модели, в соответствии с установленным **learning_rate = $\\eta$**: $\\beta^{(n+1)} = \\beta^{(n)} - \\eta \\cdot \\nabla Q(\\beta^{(n)})$\n",
    "\n",
    "- **learn**: производит итерации обучения до того момента, пока не сработает критерий останова обучения. В этот раз критерием останова будет следующее событие: во время крайней итерации изменение в функционале качества модели составило значение меньшее, чем **self.threshold**. Иными словами, $|Q(\\beta^{(n)}) - Q(\\beta^{(n+1)})| < threshold$.\n",
    "\n",
    "P.S. установите в **__init__** аттрибут экземпляра с названием **iteration_loss_dict**, который будет устроен следующим образом: на каждой итерации мы будем добавлять в словарь пару ключ-значение, где ключем будет номер итерации $n$, а значением - среднеквадратическая ошибка в точке $\\beta^{(n)}$. Это пригодится нам в будущем для визуализации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a56f14",
   "metadata": {},
   "source": [
    "### Hint: пример вычисления производной"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf18a4f6",
   "metadata": {},
   "source": [
    "$$\n",
    "Q(a, X) = \\frac{1}{N}\\cdot\\sum_{i=1}^N (\\beta_1 \\cdot d_{i1} + ... + \\beta_n \\cdot d_{in} - y_i)^2\n",
    "$$\n",
    "\n",
    "Выше - минимизируемая функция. Она зависит от n переменных: $\\beta_1, ..., \\beta_n$. Вектор-градиент - матрица с одной строчкой, состоящей из производных 1го порядка по всем переменным.\n",
    "\n",
    "$$\n",
    "\\nabla Q(a, X) = (Q'_{\\beta_1} \\;\\;\\; Q'_{\\beta_2} \\;\\;\\; ... \\;\\;\\; Q'_{\\beta_{n-1}}  \\;\\;\\;  Q'_{\\beta_n})\n",
    "$$\n",
    "\n",
    "Пример вычисления производной по первой переменной:\n",
    "\n",
    "$$\n",
    "Q'_{\\beta_1} = \\frac{2}{N} \\cdot \\sum_{i=1}^N d_{i1} (\\beta_1 \\cdot d_{i1} + ... + \\beta_{n} \\cdot d_{in} - y_i)\n",
    "$$\n",
    "\n",
    "Скажем, для нашего датасета X, Y вычислим эту саму производную при начальных единичных коэффициентах $\\beta_{start} = (1 \\;\\;\\; 1 \\;\\;\\; ...)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e55232a",
   "metadata": {},
   "source": [
    "Получим для каждого объекта в начале выражение из скобочек: \n",
    "$$\n",
    "\\beta_1 \\cdot d_{i1} + ... + \\beta_{n} \\cdot d_{in} - y_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e400e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.24339854 3.9524118  5.16354431 5.05108987 3.70336585 5.97562576\n",
      " 5.36645618 4.64371227 5.31215445 5.13559383 4.57902419 4.32294422\n",
      " 5.54997113 3.38646272 5.46648432 4.15761811 4.54622922 4.92460189\n",
      " 5.49512761 4.20534235 3.79440676 3.64754149 3.3861493  5.28347287\n",
      " 4.63170572 3.82066088 5.70447535 5.00305454 5.18649487 4.32348734\n",
      " 5.37919592 5.30162516 4.73808802 4.58758426 5.64623264 3.92151158\n",
      " 5.52622189 4.56147026 3.64504638 5.78092671 4.37963386 3.73847398\n",
      " 4.56174807 5.42891712 5.33241798 4.92249654 4.00705898 4.96133463\n",
      " 4.00952333 3.54853568 5.57722518 3.6827849  4.36082279 5.8455649\n",
      " 4.66986831 6.65566972 4.363927   3.24811339 4.12653761 4.29553237\n",
      " 4.10798391 4.87482995 5.62744705 4.99671407 4.75811197 4.45837844\n",
      " 6.02034933 2.88183343 4.30169734 6.13075889 6.25145428 5.46300566\n",
      " 5.09670393 3.39861176 4.45886785 4.42007817 6.14577431 5.96881144\n",
      " 5.27359872 4.32991041 6.64957318 5.67765577 4.74732862 5.47829417\n",
      " 5.92707771 5.91747901 3.20068905 6.20800637 4.72749617 4.7198374\n",
      " 4.86086467 5.07485189 3.71362255 6.67735332 5.63441459 4.58874102\n",
      " 5.56378844 5.35904486 4.54785033 5.09498255 5.81332403 6.70430488\n",
      " 4.33204698 5.80105232 5.56430441 4.67642147 4.45731006 4.63948485\n",
      " 7.02594262 4.25869412 4.10718147 5.41882527 3.03969722 4.59411461\n",
      " 5.48412927 6.13978611 5.54987552 5.28536325 5.1441311  4.91513358\n",
      " 3.55221989 5.56782179 5.92270183 6.08473145 5.65582014 6.72796717\n",
      " 5.89250449 4.32701823 5.05409759 3.43339313 5.13458035 5.21770945\n",
      " 3.05395059 5.99588868 5.42728653 5.09793712 6.36518637 4.36040525\n",
      " 5.41427176 5.80513674 4.02007445 6.11277334 6.14042499 6.00433222\n",
      " 5.96352138 6.498183   5.80078058 5.20005226 4.38580468 4.2267163\n",
      " 5.59697631 6.91840235 5.49735748 5.737413   5.6186477  3.8410995\n",
      " 5.1892926  3.22969448 5.53585173 4.97476892 4.28864334 5.79084199\n",
      " 5.62075696 6.05368247 4.9227938  5.20098691 4.84453557 5.73840851\n",
      " 4.51468208 4.13296691 5.4092639  5.9971191  4.97545366 5.57786105\n",
      " 5.05024326 4.54729778 5.18818061 4.73515701 3.86942418 4.3386651\n",
      " 3.88121259 5.86561083 5.840046   5.70087334 6.41799613 4.15352742\n",
      " 3.55991301 3.90012715 4.9326414  5.33903278 5.95547315 4.09464206\n",
      " 3.56409148 4.48271981 4.26983939 4.81452344 3.88809462 6.10039406\n",
      " 3.49063931 5.20087487 3.6991728  6.24531691 5.85421242 3.74118565\n",
      " 5.32581584 3.58576687 4.77178974 3.992105   6.37618337 4.93784871\n",
      " 6.74155221 4.54800448 5.22842475 5.32522464 5.79538    5.01970772\n",
      " 6.22350337 4.74205958 3.89584713 4.10913879 6.27801778 5.94066388\n",
      " 5.33956306 5.5101027  3.80404956 5.99010027 4.45672571 5.6095943\n",
      " 3.93185827 5.20181791 5.10637861 5.0082746  5.04829073 6.03846582\n",
      " 5.88570612 5.73783871 5.10750272 3.18832588 4.64862602 4.35150319\n",
      " 4.66387872 3.74370428 5.24601941 6.02310834 4.34979573 4.06591564\n",
      " 6.20435721 5.86317181 5.59461004 6.9597005  5.80785916 4.29134238\n",
      " 4.55646063 4.9994823  5.07879582 4.4794166  5.0836008  5.81060091\n",
      " 4.72032798 6.14263123 4.92535361 4.55631317 4.44413104 4.54579312\n",
      " 4.66588079 4.5066898  4.2780794  4.25249654 3.44330923 4.37941294\n",
      " 3.10300296 7.02119051 5.29135568 6.05921766 5.1477707  4.2868617\n",
      " 5.24457858 4.87394037 5.44631657 4.90965592 3.75443813 4.208688\n",
      " 4.13245386 4.53797893 4.81475757 5.46741635 6.66804295 4.65314365\n",
      " 4.99610311 4.78401454 5.02814311 6.77615823 4.59772937 4.82459629\n",
      " 4.55095591 5.7229353  3.67639162 5.05954926 4.45626754 6.32027995\n",
      " 4.80687979 5.4670546  5.69082312 4.7225595  4.46607614 4.73025166\n",
      " 5.21935156 5.00336223 4.30155283 4.10291066 5.41306994 2.42143269\n",
      " 4.20205605 3.7503951  5.0713033  5.88827853 5.81483256 4.72046397\n",
      " 5.21176717 4.87485538 5.78279164 5.85187128 6.97388958 5.07150855\n",
      " 3.15422016 4.67735587 5.40202993 5.40200364 3.99206576 6.61332644\n",
      " 3.91821036 4.52119613 5.94751874 5.91870463 3.64820347 5.45749086\n",
      " 5.97624769 4.49220575 5.76293726 4.39572426 3.33138462 4.79413552\n",
      " 6.43290512 3.53890622 5.41473731 4.66673184 4.77690279 4.8876822\n",
      " 4.40082937 4.14407205 4.63401844 4.14247423 4.44108818 5.34490912\n",
      " 6.52821223 6.81423021 6.28139112 4.40957323 4.07865498 5.35833894\n",
      " 5.55930242 3.19797292 5.04504505 4.81463953 5.56536552 5.37855056\n",
      " 5.78489876 5.25283809 4.9950704  6.28033591 4.81051934 4.99619038\n",
      " 3.14112074 4.3748927  2.74600306 5.41658302 4.83456326 6.21564233\n",
      " 3.33714112 4.48318268 6.51102943 6.52081257 5.85236786 5.90428748\n",
      " 4.03560214 4.9202838  6.10024577 4.61821235 4.21304828 4.65330445\n",
      " 5.43078472 5.1454396  5.7352727  6.25687435 5.09038301 5.85546481\n",
      " 5.20282063 5.32830415 5.61099369 6.74782444 4.62762964 4.03292975\n",
      " 4.44326753 4.27066883 6.46501274 4.0048406  5.90945756 6.0153974\n",
      " 3.85796245 5.25204778 4.81794991 6.7201739  5.30147851 4.16828667\n",
      " 6.04567738 3.59670482 3.69694272 2.94076844 4.7740356  4.65280046\n",
      " 4.19575194 2.74661554 4.48160073 4.99353345 5.81397409 5.08112851\n",
      " 5.67363201 4.71253121 4.55869315 5.32196079 4.35196605 6.46070921\n",
      " 2.7290341  4.9824969  6.69329686 4.27190386 4.80619581 5.04537559\n",
      " 3.68936935 5.47911852 4.90946813 5.34021591 5.17150853 4.27341889\n",
      " 4.16478592 5.12308255 5.96304303 3.40022361 4.59707071 2.52247626\n",
      " 5.34388579 4.67052741 4.13170341 5.84170886 4.7399409  5.4471343\n",
      " 3.58031473 5.51200689 4.9672056  4.53642663 3.64701032 5.5760156\n",
      " 5.99914493 5.96966446 3.89192742 4.81024577 6.40789903 5.20514712\n",
      " 3.90115832 5.46340749 4.78486966 3.9010564  2.8216796  4.76720255\n",
      " 5.93446267 4.64203082 4.10414963 3.88003353 5.45298348 3.81541181\n",
      " 4.22890945 3.7535356  4.88358028 4.60044845 4.78015001 4.74902189\n",
      " 3.76701335 5.63243667 5.80212623 5.63108424 5.95987506 5.82333881\n",
      " 5.34234482 4.35445587 5.63675209 5.66068113 7.02221803 4.69531619\n",
      " 5.29858141 5.16592783 4.6291466  4.59450996 6.38480787 4.30890953\n",
      " 5.8235605  4.51229876 5.92514607 4.9959867  3.28820705 4.27989309\n",
      " 4.6863167  5.44237127 6.56354983 5.81303396 5.93683055 5.4582393\n",
      " 6.36494677 4.72556141 4.27269274 3.96566177 5.64320243 5.71976797\n",
      " 5.87137271 6.11188048 5.33275503 6.08594578 5.23973073 5.67319016\n",
      " 4.62503569 3.70282614 4.85979582 4.49914211 6.3288355  3.07659622\n",
      " 5.83118192 5.01392009 4.727517   4.70928992 5.09051916 5.28006406\n",
      " 3.99382578 3.94961972 4.05602961 6.65220396 2.60955193 5.59390933\n",
      " 5.77488167 4.38928811 5.00579695 5.59593581 3.54619657 4.28936338\n",
      " 4.38051029 5.71795927 4.08884796 4.13526388 4.12713822 3.67545107\n",
      " 4.06460194 3.47846535 4.18977634 3.81541455 5.29132211 4.41128107\n",
      " 5.68632139 5.11360661 5.96063637 4.13671604 5.82188771 5.18110473\n",
      " 5.37432644 5.72199702 3.31440837 4.6048895  5.2336486  5.69899565\n",
      " 5.33799461 4.55181685 5.80836756 5.35899579 4.36962223 4.81781935\n",
      " 6.07897482 6.0337783  4.57254656 6.48572097 4.29707163 5.5412812\n",
      " 4.66305855 4.27090039 3.62894394 5.63719896 3.46578661 4.30289746\n",
      " 4.62343334 3.19486327 5.83541483 4.36663484 5.11643756 5.77209379\n",
      " 2.56754591 5.83273808 5.29910343 4.34940481 5.77195905 2.7844016\n",
      " 6.87398971 4.21804499 5.43026424 4.76361556 4.91127461 6.04173968\n",
      " 5.29078687 7.62302473 4.64632338 6.24255584 4.67210275 6.22873404\n",
      " 5.60478222 4.96275355 4.62688572 6.46774207 3.864104   6.18319581\n",
      " 5.90961827 5.49011476 5.16822939 6.63958453 5.55570108 3.85773898\n",
      " 4.99505808 4.35323681 4.21567458 4.48703947 4.83999871 4.32884024\n",
      " 6.04980772 6.97822393 4.68165894 4.41027256 4.99153307 4.24243307\n",
      " 3.8137676  4.30086405 2.62184408 6.00706093 5.81926685 5.82833635\n",
      " 4.74785597 6.16513712 5.61827069 3.41939678 4.75373198 5.54400186\n",
      " 5.1778535  5.04462496 4.12392904 5.49126513 4.00819384 3.01311585\n",
      " 5.13604532 4.86192723 5.08013398 4.51524908 5.51092565 5.07975611\n",
      " 3.86372907 4.51305974 6.96592211 4.8566596  5.24273365 4.29030916\n",
      " 4.6784091  4.59887997 4.09258243 5.10297709 6.11512699 5.18538883\n",
      " 3.87664114 5.69908822 5.0933567  6.80252411 5.80682864 3.82732619\n",
      " 4.11470205 6.56293081 6.68931514 3.7693078  5.26071563 3.32428994\n",
      " 4.59162478 4.56903742 5.57187804 4.35519327 4.51346657 4.28055666\n",
      " 3.94977456 5.36365464 3.77786946 4.76672948 6.17394415 5.14351005\n",
      " 6.44597515 4.88097171 5.88624148 5.02841353 4.23145875 6.61883143\n",
      " 6.0020936  3.32967634 6.12413728 4.99250535 5.40843842 4.61858143\n",
      " 5.99204165 4.74338874 3.9672816  4.29734835 4.3574398  4.45863736\n",
      " 5.7337239  6.51930501 7.10688902 5.73632904 3.94789473 4.61012956\n",
      " 4.39008257 3.80060636 4.75113997 5.3160908  4.31156203 3.79225584\n",
      " 4.97270971 4.28464429 5.11258725 4.99357878 4.34292039 3.71381258\n",
      " 4.69787804 4.30961581 5.49561872 5.78065388 6.37536318 4.63527922\n",
      " 4.76796349 5.84384839 5.47325649 4.51144329 5.98553661 5.51015885\n",
      " 3.75887922 4.69765964 5.81368727 3.45499929 3.90171375 5.7828839\n",
      " 4.56460503 5.66043422 4.4543095  7.02174835 5.65315344 5.5786657\n",
      " 6.17452063 6.261164   5.4402153  3.81259795 5.24891625 4.49719476\n",
      " 5.34742097 4.44025909 4.03239131 3.74455919 6.65545284 4.55780115\n",
      " 3.84706031 4.10345816 4.36027953 4.52297387 4.35728239 4.39833935\n",
      " 4.94451667 3.44589036 5.67304958 3.56466953 4.16963277 5.59602141\n",
      " 3.5974561  4.26649727 5.72205165 4.70854041 3.5026524  6.08031929\n",
      " 4.03696951 4.14322996 5.28503866 3.97287206 3.53874807 3.14594206\n",
      " 6.78582883 2.91122666 3.64791199 4.75471216 5.01513347 4.58409273\n",
      " 4.67145661 5.18510051 5.32917746 6.31949051 4.35104469 6.00300872\n",
      " 4.74207367 4.17437684 3.46932896 5.82304419 4.80475527 5.12305911\n",
      " 6.17295424 5.04190082 4.40840946 4.47410606 4.38597156 5.33383401\n",
      " 3.79941819 4.84902464 5.10834683 4.14932475 5.11371631 5.37600576\n",
      " 6.45842905 4.29066316 3.64159281 5.81575505 4.65493246 5.08558541\n",
      " 4.75211938 4.53201877 5.26760995 5.89550202 4.36948339 5.80878294\n",
      " 4.76322144 4.69398957 3.07414067 4.12253716 5.69415721 5.39422558\n",
      " 5.32802806 4.74273509 5.66261832 5.67134799 3.24190629 4.00742419\n",
      " 4.92814607 5.53282323 5.08600332 5.2654927  5.6756579  5.44699762\n",
      " 4.12617511 4.36985504 5.45261303 4.15313035 5.70783136 4.67966389\n",
      " 5.71004923 5.06455785 4.34259328 5.40060052 4.71576245 5.42463358\n",
      " 5.84593367 5.0412125  5.42904134 6.44717073 5.64916097 4.63141451\n",
      " 3.93942824 4.08711444 5.68661968 4.99819077 4.90783468 4.09463863\n",
      " 5.59305049 4.52339777 5.18918336 4.50232406 4.62759611 3.05952626\n",
      " 4.77735151 6.00342063 5.44580419 5.77199916 5.49596001 5.25934707\n",
      " 6.44616423 4.85284879 4.27967088 3.76737652 4.32871303 6.14647881\n",
      " 4.26026023 6.64252238 6.38328012 4.09981583 3.3685002  3.74027592\n",
      " 3.63309909 5.85438194 3.32996588 5.76637992 4.44570526 5.01073321\n",
      " 2.44153417 5.0742834  5.73171777 4.66953407 4.89988464 4.1806066\n",
      " 6.40513534 5.13366051 6.66606293 6.0030171  3.62528462 6.01020588\n",
      " 6.39315976 5.37674879 5.22961799 4.59870235 4.76520225 5.47235694\n",
      " 5.50725118 6.33656326 6.4907621  4.70748836 5.87134315 5.49075516\n",
      " 5.24559589 4.87454847 5.64110939 5.46281503 4.20446616 4.70749824\n",
      " 4.22308243 5.9134398  6.28455876 4.88393457 4.17620696 6.1447345\n",
      " 5.14706559 5.84837912 3.85477248 4.68510219 4.39964226 3.08536651\n",
      " 6.29125435 4.86297434 3.90051671 4.4086249  4.03554096 5.03161912\n",
      " 5.21650125 4.06573163 5.4020003  4.70179308 5.95784083 5.53108864\n",
      " 2.81175951 5.4780017  5.64968319 5.86938944 5.65391851 4.8154316\n",
      " 6.27309253 4.10139201 5.25749574 6.5262721  5.49244913 3.75061743\n",
      " 3.61368238 4.92161399 4.77456866 3.26062548 6.61765019 6.67535586\n",
      " 6.10326294 6.18461481 4.28122785 5.76402405 4.74999633 5.81525515\n",
      " 5.0887531  5.70693965 4.5461498  4.83973082 4.45246661 4.6631349\n",
      " 4.61718083 5.42923087 6.02803474 4.46853896]\n"
     ]
    }
   ],
   "source": [
    "### Инициализируем точку для коэффициентов в виде вектора из единичек\n",
    "initial_betas = np.ones(X.shape[1])\n",
    "\n",
    "### Получим выражение выше для каждого объекта. \n",
    "### Для этого скалярно перемножим строчки из X на наши beta\n",
    "\n",
    "scalar_value = np.dot(X, initial_betas.reshape(-1, 1)).ravel()\n",
    "print(scalar_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97eff07",
   "metadata": {},
   "source": [
    "Теперь полученное значение для каждого объекта умножим на соответствующее значение признака $d_1$:\n",
    "\n",
    "$$\n",
    "d_{i1} \\cdot (\\beta_1 \\cdot d_{i1} + ... + \\beta_{n} \\cdot d_{in} - y_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccada8b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Возьмем столбик со значениями 1 признака\n",
    "\n",
    "d_i1 = X.values[:, 0]\n",
    "### Умножим каждый объект на соответствующее значение признака\n",
    "scalar_value = scalar_value * d_i1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0c9a216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.30115305614268"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Наконец, умножим все на 2 и усреднимся, \n",
    "### чтобы получить значение производной по первому параметру\n",
    "\n",
    "2 * np.mean(scalar_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad03b6b6",
   "metadata": {},
   "source": [
    "### Эта логика поможем Вам при реализации класса!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1782ba",
   "metadata": {},
   "source": [
    "learn(self)\n",
    "\n",
    "метод возвращает итоговую среднеквадратическую ошибку.\n",
    "метод итеративно вычисляет среднеквадратическую ошибку и вектор-градиент. номер итерации и MSE записываются в словарь *iteration_loss_dict*. критерий останова срабатывает тогда, когда абсолютное значение разницы двух последних MSE меньше *self.threshold*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97fa5c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GradientDescentMse:\n",
    "    \"\"\"\n",
    "    Базовый класс для реализации градиентного спуска в задаче линейной МНК регрессии\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, samples: pd.DataFrame, targets: pd.DataFrame,\n",
    "                 learning_rate: float = 1e-3, threshold=1e-6, copy: bool = True):\n",
    "        \"\"\"\n",
    "        self.samples - матрица признаков\n",
    "        self.targets - вектор таргетов\n",
    "        self.beta - вектор из изначальными весами модели == коэффициентами бета (состоит из единиц)\n",
    "        self.learning_rate - параметр *learning_rate* для корректировки нормы градиента\n",
    "        self.threshold - величина, меньше которой изменение в loss-функции означает остановку градиентного спуска\n",
    "        iteration_loss_dict - словарь, который будет хранить номер итерации и соответствующую MSE\n",
    "        copy: копирование матрицы признаков или создание изменения in-place\n",
    "        \"\"\"\n",
    "        self.samples = samples\n",
    "        self.targets = targets\n",
    "        self.beta = np.ones(self.samples.shape[1])\n",
    "        self.learning_rate = learning_rate\n",
    "        self.threshold = threshold\n",
    "        self.iteration_loss_dict = {}\n",
    "        self.copy = copy\n",
    "\n",
    "\n",
    "    def add_constant_feature(self):\n",
    "        \"\"\"\n",
    "        Метод для создания константной фичи в матрице объектов samples\n",
    "        Метод создает колонку с константным признаком (interсept) в матрице признаков.\n",
    "        Hint: так как количество признаков увеличилось на одну, не забудьте дополнить вектор с изначальными весами модели!\n",
    "        \"\"\"\n",
    "        self.samples['constant'] = 1\n",
    "\n",
    "        self.beta = np.ones(self.samples.shape[1])\n",
    "\n",
    "        if not self.copy:\n",
    "            return\n",
    "\n",
    "    def calculate_mse_loss(self) -> float:\n",
    "        \"\"\"\n",
    "        Метод для расчета среднеквадратической ошибки\n",
    "\n",
    "        :return: среднеквадратическая ошибка при текущих весах модели : float\n",
    "        \"\"\"\n",
    "        predicted = np.dot(self.samples, self.beta)\n",
    "\n",
    "        mse = np.mean((predicted - self.targets) ** 2)\n",
    "        return mse\n",
    "\n",
    "    def calculate_gradient(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Метод для вычисления вектора-градиента\n",
    "        Метод возвращает вектор-градиент, содержащий производные по каждому признаку.\n",
    "        Сначала матрица признаков скалярно перемножается на вектор self.beta, и из каждой колонки\n",
    "        полученной матрицы вычитается вектор таргетов. Затем полученная матрица скалярно умножается на матрицу признаков.\n",
    "        Наконец, итоговая матрица умножается на 2 и усредняется по каждому признаку.\n",
    "\n",
    "        :return: вектор-градиент, т.е. массив, содержащий соответствующее количество производных по каждой переменной : np.ndarray\n",
    "        \"\"\"\n",
    "        a = np.dot(self.samples, self.beta)\n",
    "        b = a - self.targets\n",
    "        ans = (np.dot(b, self.samples) * 2) / len(self.samples)\n",
    "        return ans\n",
    "\n",
    "    def iteration(self):\n",
    "        \"\"\"\n",
    "        Обновляем веса модели в соответствии с текущим вектором-градиентом\n",
    "        \"\"\"\n",
    "        b = self.calculate_gradient()\n",
    "        self.beta -= self.learning_rate * b\n",
    "\n",
    "    def learn(self):\n",
    "        \"\"\"\n",
    "        Итеративное обучение весов модели до срабатывания критерия останова\n",
    "        Запись mse и номера итерации в iteration_loss_dict\n",
    "\n",
    "        Описание алгоритма работы для изменения бет:\n",
    "            Фиксируем текущие beta -> start_betas\n",
    "            Делаем шаг градиентного спуска\n",
    "            Записываем новые beta -> new_betas\n",
    "            Пока |L(new_beta) - L(start_beta)| > threshold:\n",
    "                Повторяем первые 3 шага\n",
    "\n",
    "        Описание алгоритма работы для изменения функции потерь:\n",
    "            Фиксируем текущие mse -> previous_mse\n",
    "            Делаем шаг градиентного спуска\n",
    "            Записываем новые mse -> next_mse\n",
    "            Пока |(previous_mse) - (next_mse)| > threshold:\n",
    "                Повторяем первые 3 шага\n",
    "        \"\"\"\n",
    "        previous_mse = self.calculate_mse_loss()\n",
    "        self.iter_count = 0\n",
    "        while True:\n",
    "            self.iteration()\n",
    "            next_mse = self.calculate_mse_loss()\n",
    "\n",
    "            self.iteration_loss_dict[self.iter_count] = next_mse\n",
    "\n",
    "            if abs(previous_mse - next_mse) < self.threshold:\n",
    "                break\n",
    "\n",
    "            previous_mse = next_mse\n",
    "            self.iter_count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87e2e4a",
   "metadata": {},
   "source": [
    "Обучим коэффициенты линейной модели с помощью реализованного нами градиентного спуска, не забыв добавить свободную переменную. Получились ли такие же коэффициенты, как и при использовании **LinearRegression** из **sklearn**? Если нет, то почему они отличаются, на Ваш взгляд, и сильно ли?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9432fd80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "904abab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88733305 1.90100713 2.88063607 3.87662612 4.89623507 5.89126182\n",
      " 6.89254811 7.90311947 8.87580109 9.86109585 4.94854733]\n",
      "0.010732740689782506\n"
     ]
    }
   ],
   "source": [
    "GD = GradientDescentMse(samples=X, targets=Y)\n",
    "GD.add_constant_feature()\n",
    "GD.learn()\n",
    "print(GD.beta)\n",
    "print(GD.calculate_mse_loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0.01, 0.1': [0.42914450820919203, 98], '0.01, 0.05': [0.7933106723839498, 152], '0.01, 0.01': [2.3084563042218504, 271], '0.01, 0.005': [3.317604378398448, 162], '0.01, 0.001': [3.4188440110378284, 502], '0.001, 0.1': [0.13930745981563908, 200], '0.001, 0.05': [0.04191600215652436, 324], '0.001, 0.01': [0.44096699878774426, 988], '0.001, 0.005': [0.8060077108681554, 1522], '0.001, 0.001': [2.3139393273900146, 2709], '0.0001, 0.1': [0.11244969609548172, 417], '0.0001, 0.05': [0.14758909576416868, 688], '0.0001, 0.01': [0.13561442389653577, 2009], '0.0001, 0.005': [0.03803198592345847, 3244], '0.0001, 0.001': [0.4430542743091843, 9881], '1e-05, 0.1': [0.037352129147760205, 664], '1e-05, 0.05': [0.05278662720066507, 1180], '1e-05, 0.01': [0.11264763801782673, 4179], '1e-05, 0.005': [0.14751404098538867, 6888], '1e-05, 0.001': [0.13525905667795768, 20100]}\n"
     ]
    }
   ],
   "source": [
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4772fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Веса модели при переменных d1, d2, ..., d10 равны соответственно: \\n\\n' + str(GD.beta))\n",
    "print(GD.iteration_loss_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eafa6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Укажите в ответе на задание 2 оценку свободного коэффициента"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4679a008",
   "metadata": {},
   "source": [
    "Попробуйте теперь изменить значения **learning_rate** и/или **threshold**. Например, установите длину шага $\\eta = 1$. Что произошло и почему такое возможно?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec321ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code is here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2ad41c",
   "metadata": {},
   "source": [
    "В машинном обучении зачастую исследуют так называемые **траектории обучения** (или **learning paths**). Это графики, показывающие, как во время обучения при каждой следующей итерации изменялось значение минимизируемого функционала. Постройте такие траектории для различных **learning rate**'ов и **threshold**'ов. Советуем использовать для этого разобранный на занятиях **add_subplot** метод. \n",
    "\n",
    "Возьмите следующие **threshold**'ы: 1e-2, 1e-3, 1e-4, 1e-5\n",
    "\n",
    "И следующие значения **learning rate**'а: 1e-1, 5e-2, 1e-2, 5e-3, 1e-3\n",
    "\n",
    "У вас должен получиться примерно такой график (см. ниже, значения среднеквадратической ошибки мы намеренно замазали оранжевыми квадратиками, чтобы не спойлерить вам результаты).\n",
    "\n",
    "Как и подобает хорошим Data Scientist'ам, не забывайте подписывать графики, оси, а так же делать элементы ваших визуализаций читаемыми и видимыми. Советуем пересмотреть методы и параметры форматирования из лекции.\n",
    "\n",
    "При какой комбинации **threshold** - **learning rate** из возможных предложенных выше, получается достигнуть меньшего значения нашей минимизируемой функции? Запишите каждой из значений в легенде на графиках.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "c246cf04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'thresholds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[461], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"Задать списки для итераций\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m### Your code is here \u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mthresholds\u001b[49m)):\n\u001b[0;32m      9\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Задать threshold, добавить график на полонто, создать список для хранения значений функционала\"\"\"\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m### Your code is here\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'thresholds' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1300x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "fig.set_size_inches(13, 10)\n",
    "\n",
    "\"\"\"Задать списки для итераций\"\"\"\n",
    "### Your code is here \n",
    "\n",
    "for i in range(len(thresholds)):\n",
    "    \"\"\"Задать threshold, добавить график на полонто, создать список для хранения значений функционала\"\"\"\n",
    "    ### Your code is here\n",
    "    \n",
    "    for lr in rates:\n",
    "        \"\"\"Создать объект модели, добавить константу, запустить обучение модели\"\"\"\n",
    "        ### Your code is here\n",
    "        \n",
    "        \"\"\"Определить learning_path через атрибут iteration_loss_dict\"\"\"\n",
    "        ### Your code is here\n",
    "        \n",
    "        \"\"\"Отобразить learning_path на графике\"\"\"\n",
    "        ### Your code is here\n",
    "        plt.ylim(0, 100)\n",
    "        plt.xlim(0, 2000)\n",
    "        \n",
    "        Q_values.append(str(round(list(learning_path.values())[-1], ndigits=4)))\n",
    "    \n",
    "    plt.ylabel('Среднеквадратическая ошибка')\n",
    "    plt.xlabel('Номер итерации')\n",
    "    plt.legend([f'Learning rate equals to {rates[i]}' + ' with Q = ' + Q_values[i] for i in range(len(rates))])\n",
    "\n",
    "fig.tight_layout() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c68821",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Укажите в ответе на задание 3 значения threshold и learning rate через запятую и пробел \n",
    "### (при которых достигается меньшее значение минимизируемой функции)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
